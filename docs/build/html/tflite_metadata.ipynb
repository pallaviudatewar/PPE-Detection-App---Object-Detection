{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSRG6qmtTRSk"
   },
   "source": [
    "# TensorFlow Lite Metadata Writer API\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding metadata to TensorFlow Lite models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorFlow Lite metadata provides a standard for model descriptions. The metadata is an important source of knowledge about what the model does and its input / output information.**\n",
    "\n",
    "**The metadata consists of both**\n",
    "a. human readable parts which convey the best practice when using the model, and  \n",
    "\n",
    "b. machine readable parts that can be leveraged by code generators, such as the TensorFlow Lite Android code generator and the Android Studio ML Binding feature.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Install support for tf nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-8xSrSvUg-6",
    "outputId": "616c7f32-7ba9-456b-f3d9-eacdeaf379eb"
   },
   "outputs": [],
   "source": [
    "!pip install tflite-support-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The ObjectDetector API expects a TFLite model with mandatory TFLite Model Metadata.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-HUTEtHuf0n"
   },
   "source": [
    "**Step 2:** Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_NIROeouf0o"
   },
   "outputs": [],
   "source": [
    "from tflite_support.metadata_writers import object_detector\n",
    "from tflite_support.metadata_writers import writer_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMapb_FtHbRN"
   },
   "source": [
    "**Step 3:** Create metadata writer and populate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMGGeJfCuf0p",
    "outputId": "7986ad86-94df-4cf3-a298-03009d57bc38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"ObjectDetector\",\n",
      "  \"description\": \"Identify which of a known set of objects might be present and provide information about their positions within the given image or a video stream.\",\n",
      "  \"subgraph_metadata\": [\n",
      "    {\n",
      "      \"input_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"image\",\n",
      "          \"description\": \"Input image to be detected.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"ImageProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"color_space\": \"RGB\"\n",
      "            }\n",
      "          },\n",
      "          \"process_units\": [\n",
      "            {\n",
      "              \"options_type\": \"NormalizationOptions\",\n",
      "              \"options\": {\n",
      "                \"mean\": [\n",
      "                  127.5\n",
      "                ],\n",
      "                \"std\": [\n",
      "                  127.5\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              -1.0\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"location\",\n",
      "          \"description\": \"The locations of the detected boxes.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"BoundingBoxProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"index\": [\n",
      "                1,\n",
      "                0,\n",
      "                3,\n",
      "                2\n",
      "              ],\n",
      "              \"type\": \"BOUNDARIES\"\n",
      "            },\n",
      "            \"range\": {\n",
      "              \"min\": 2,\n",
      "              \"max\": 2\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"category\",\n",
      "          \"description\": \"The categories of the detected boxes.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"FeatureProperties\",\n",
      "            \"content_properties\": {\n",
      "            },\n",
      "            \"range\": {\n",
      "              \"min\": 2,\n",
      "              \"max\": 2\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "          },\n",
      "          \"associated_files\": [\n",
      "            {\n",
      "              \"name\": \"labelmap.txt\",\n",
      "              \"description\": \"Labels for categories that the model can recognize.\",\n",
      "              \"type\": \"TENSOR_VALUE_LABELS\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"score\",\n",
      "          \"description\": \"The scores of the detected boxes.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"FeatureProperties\",\n",
      "            \"content_properties\": {\n",
      "            },\n",
      "            \"range\": {\n",
      "              \"min\": 2,\n",
      "              \"max\": 2\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"number of detections\",\n",
      "          \"description\": \"The number of the detected boxes.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"FeatureProperties\",\n",
      "            \"content_properties\": {\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_groups\": [\n",
      "        {\n",
      "          \"name\": \"detection_result\",\n",
      "          \"tensor_names\": [\n",
      "            \"location\",\n",
      "            \"category\",\n",
      "            \"score\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ObjectDetectorWriter = object_detector.MetadataWriter\n",
    "_MODEL_PATH = \"/content/drive/MyDrive/TensorFlow/workspace/training_demo/Tensorflow Lite Model/converted_model.tflite\"\n",
    "# Task Library expects label files that are in the same format as the one below.\n",
    "_LABEL_FILE = \"/content/drive/MyDrive/TensorFlow/workspace/training_demo/annotations/labelmap.txt\"\n",
    "_SAVE_TO_PATH = \"/content/drive/MyDrive/TensorFlow/workspace/training_demo/metadata_tflite/detect.tflite\"\n",
    "# Normalization parameters is required when reprocessing the image. It is\n",
    "# optional if the image pixel values are in range of [0, 255] and the input\n",
    "# tensor is quantized to uint8. See the introduction for normalization and\n",
    "# quantization parameters below for more details.\n",
    "# https://www.tensorflow.org/lite/convert/metadata#normalization_and_quantization_parameters)\n",
    "_INPUT_NORM_MEAN = 127.5\n",
    "_INPUT_NORM_STD = 127.5\n",
    "\n",
    "# Create the metadata writer.\n",
    "writer = ObjectDetectorWriter.create_for_inference(\n",
    "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
    "    [_LABEL_FILE])\n",
    "\n",
    "# Verify the metadata generated by metadata writer.\n",
    "print(writer.get_metadata_json())\n",
    "\n",
    "# Populate the metadata into the model.\n",
    "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PPE_TensorFlow_Object_Detection_API.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
